{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "from torchtsmixer import TSMixer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data_imu_birlestirilmis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class Name\"]=label_encoder.fit_transform(df[\"Class Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falling' 'not_falling']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>gz</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.091892</td>\n",
       "      <td>8.707838</td>\n",
       "      <td>1.765225</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>1900-01-01 17:44:42.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.083568</td>\n",
       "      <td>8.732087</td>\n",
       "      <td>1.765318</td>\n",
       "      <td>-0.036781</td>\n",
       "      <td>0.064346</td>\n",
       "      <td>-0.036686</td>\n",
       "      <td>1900-01-01 17:44:42.020000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.075247</td>\n",
       "      <td>8.756325</td>\n",
       "      <td>1.765411</td>\n",
       "      <td>-0.037166</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>-0.036976</td>\n",
       "      <td>1900-01-01 17:44:42.040000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.066932</td>\n",
       "      <td>8.780539</td>\n",
       "      <td>1.765503</td>\n",
       "      <td>-0.037551</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>1900-01-01 17:44:42.060000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.058625</td>\n",
       "      <td>8.804720</td>\n",
       "      <td>1.765596</td>\n",
       "      <td>-0.037936</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>-0.037553</td>\n",
       "      <td>1900-01-01 17:44:42.080000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51645</th>\n",
       "      <td>51645</td>\n",
       "      <td>1.611913</td>\n",
       "      <td>8.047413</td>\n",
       "      <td>-3.202833</td>\n",
       "      <td>-0.106623</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.050371</td>\n",
       "      <td>1900-01-01 17:59:15.899794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51646</th>\n",
       "      <td>51646</td>\n",
       "      <td>1.626502</td>\n",
       "      <td>8.043946</td>\n",
       "      <td>-3.201882</td>\n",
       "      <td>-0.118920</td>\n",
       "      <td>0.123886</td>\n",
       "      <td>-0.071806</td>\n",
       "      <td>1900-01-01 17:59:15.919794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51647</th>\n",
       "      <td>51647</td>\n",
       "      <td>1.641042</td>\n",
       "      <td>8.040466</td>\n",
       "      <td>-3.200937</td>\n",
       "      <td>-0.131261</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>-0.093307</td>\n",
       "      <td>1900-01-01 17:59:15.939794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51648</th>\n",
       "      <td>51648</td>\n",
       "      <td>1.655544</td>\n",
       "      <td>8.036974</td>\n",
       "      <td>-3.199998</td>\n",
       "      <td>-0.143635</td>\n",
       "      <td>0.202538</td>\n",
       "      <td>-0.114858</td>\n",
       "      <td>1900-01-01 17:59:15.959793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51649</th>\n",
       "      <td>51649</td>\n",
       "      <td>1.670022</td>\n",
       "      <td>8.033476</td>\n",
       "      <td>-3.199062</td>\n",
       "      <td>-0.156031</td>\n",
       "      <td>0.241975</td>\n",
       "      <td>-0.136441</td>\n",
       "      <td>1900-01-01 17:59:15.979793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51650 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        ax        ay        az        gx        gy        gz  \\\n",
       "0               0  1.091892  8.707838  1.765225 -0.036396  0.063694 -0.036396   \n",
       "1               1  1.083568  8.732087  1.765318 -0.036781  0.064346 -0.036686   \n",
       "2               2  1.075247  8.756325  1.765411 -0.037166  0.064996 -0.036976   \n",
       "3               3  1.066932  8.780539  1.765503 -0.037551  0.065642 -0.037265   \n",
       "4               4  1.058625  8.804720  1.765596 -0.037936  0.066281 -0.037553   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "51645       51645  1.611913  8.047413 -3.202833 -0.106623  0.084735 -0.050371   \n",
       "51646       51646  1.626502  8.043946 -3.201882 -0.118920  0.123886 -0.071806   \n",
       "51647       51647  1.641042  8.040466 -3.200937 -0.131261  0.163164 -0.093307   \n",
       "51648       51648  1.655544  8.036974 -3.199998 -0.143635  0.202538 -0.114858   \n",
       "51649       51649  1.670022  8.033476 -3.199062 -0.156031  0.241975 -0.136441   \n",
       "\n",
       "                        timestamp  Class Name  \n",
       "0      1900-01-01 17:44:42.000000           1  \n",
       "1      1900-01-01 17:44:42.020000           1  \n",
       "2      1900-01-01 17:44:42.040000           1  \n",
       "3      1900-01-01 17:44:42.060000           1  \n",
       "4      1900-01-01 17:44:42.080000           1  \n",
       "...                           ...         ...  \n",
       "51645  1900-01-01 17:59:15.899794           1  \n",
       "51646  1900-01-01 17:59:15.919794           1  \n",
       "51647  1900-01-01 17:59:15.939794           1  \n",
       "51648  1900-01-01 17:59:15.959793           1  \n",
       "51649  1900-01-01 17:59:15.979793           1  \n",
       "\n",
       "[51650 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51650 entries, 0 to 51649\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  51650 non-null  int64  \n",
      " 1   ax          51650 non-null  float64\n",
      " 2   ay          51650 non-null  float64\n",
      " 3   az          51650 non-null  float64\n",
      " 4   gx          51650 non-null  float64\n",
      " 5   gy          51650 non-null  float64\n",
      " 6   gz          51650 non-null  float64\n",
      " 7   timestamp   51650 non-null  object \n",
      " 8   Class Name  51650 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Veriler üzerinde standartlaştırma yapmak istiyorsanız, verileri modelinize vermeden önce StandardScaler gibi bir ölçekleyici ile işleyebilirsiniz. İşte nasıl ekleyebileceğinizin bir örneği:\n",
    "\n",
    "Standartlaştırmayı Eklemek İçin:\n",
    "\n",
    "StandardScaler kullanılarak her bir ax, ay, az, gx, gy, gz sütunu standartlaştırılıyor (ortalaması 0, varyansı 1 olacak şekilde).\n",
    "Bu işlemi __getitem__ fonksiyonu yerine, __init__ fonksiyonunda tüm veri setine uygulayarak yapıyoruz. Bu sayede veriler model eğitimi öncesinde ölçeklendirilmiş oluyor.\n",
    "Standartlaştırma, modelin daha hızlı ve kararlı bir şekilde öğrenmesine yardımcı olabilir, çünkü girdi verilerindeki farklı büyüklüklerdeki özelliklerin etkilerini dengeleyerek modelin dikkatini önemli desenlere yönlendirir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import stats\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.dataframe[self.features] = self.scaler.fit_transform(self.dataframe[self.features])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         \n",
    "        features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "        \n",
    "        \n",
    "        label = self.dataframe.loc[idx + self.sequence_length - 1, self.labels]\n",
    "        \n",
    "         \n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class TSMixerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.dataframe[self.features] = self.scaler.fit_transform(self.dataframe[self.features])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "            labels_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.labels].values\n",
    "\n",
    "            # Tüm etiketlerin aynı olup olmadığını kontrol et\n",
    "            if len(set(labels_sequence)) == 1:  # Tüm etiketler aynı\n",
    "                label = labels_sequence[0]\n",
    "                break  # Aynı etiket bulundu, döngüden çık\n",
    "\n",
    "            # Farklı etiketler varsa, bir sonraki indeksi kontrol et\n",
    "            idx += 1\n",
    "            if idx + self.sequence_length > len(self.dataframe):  # Sınır kontrolü\n",
    "                raise IndexError(\"Veri setinde uygun pencere kalmadı.\")\n",
    "\n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)  # (sequence_length, features_count)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TSMixerDataset(dataframe)\n",
    "\n",
    " \n",
    "labels = dataset.dataframe['Class Name'].values[:len(dataset)]   \n",
    "\n",
    " \n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    " \n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, stratify=labels)\n",
    " \n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 41300\n",
      "Test dataset size: 10326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1973,  1.4236, -0.3150,  0.0243,  0.1950,  1.7694],\n",
       "         [-0.1946,  1.4154, -0.3331,  0.0300,  0.1794,  1.7647],\n",
       "         [-0.1915,  1.4055, -0.3514,  0.0356,  0.1629,  1.7583],\n",
       "         [-0.1877,  1.3941, -0.3697,  0.0412,  0.1455,  1.7501],\n",
       "         [-0.1835,  1.3811, -0.3880,  0.0468,  0.1273,  1.7402],\n",
       "         [-0.1787,  1.3667, -0.4063,  0.0525,  0.1084,  1.7287],\n",
       "         [-0.1732,  1.3509, -0.4244,  0.0582,  0.0889,  1.7158],\n",
       "         [-0.1672,  1.3338, -0.4425,  0.0640,  0.0688,  1.7013],\n",
       "         [-0.1605,  1.3153, -0.4603,  0.0699,  0.0484,  1.6855],\n",
       "         [-0.1531,  1.2957, -0.4779,  0.0760,  0.0276,  1.6684],\n",
       "         [-0.1451,  1.2748, -0.4951,  0.0822,  0.0066,  1.6500],\n",
       "         [-0.1363,  1.2528, -0.5120,  0.0886, -0.0146,  1.6304],\n",
       "         [-0.1268,  1.2297, -0.5285,  0.0952, -0.0358,  1.6097],\n",
       "         [-0.1165,  1.2057, -0.5445,  0.1021, -0.0570,  1.5880],\n",
       "         [-0.1055,  1.1806, -0.5600,  0.1092, -0.0781,  1.5653],\n",
       "         [-0.0936,  1.1546, -0.5749,  0.1167, -0.0990,  1.5417],\n",
       "         [-0.0808,  1.1278, -0.5892,  0.1244, -0.1195,  1.5173],\n",
       "         [-0.0672,  1.1001, -0.6028,  0.1325, -0.1397,  1.4921],\n",
       "         [-0.0528,  1.0717, -0.6157,  0.1409, -0.1594,  1.4663],\n",
       "         [-0.0374,  1.0427, -0.6277,  0.1498, -0.1785,  1.4398],\n",
       "         [-0.0210,  1.0129, -0.6389,  0.1590, -0.1970,  1.4127],\n",
       "         [-0.0037,  0.9826, -0.6493,  0.1687, -0.2147,  1.3852],\n",
       "         [ 0.0145,  0.9517, -0.6586,  0.1788, -0.2316,  1.3572],\n",
       "         [ 0.0338,  0.9204, -0.6670,  0.1895, -0.2475,  1.3290],\n",
       "         [ 0.0542,  0.8886, -0.6743,  0.2006, -0.2624,  1.3004]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25  \n",
    "prediction_length = 1  \n",
    "input_channels = 6 \n",
    "output_channels = 1\n",
    "\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "criterion = criterion = nn.BCEWithLogitsLoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsmixer accuracy , lstmden daha düşük , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m features, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(labels[epoch])\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m, in \u001b[0;36mTSMixerDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         features_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m:\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     22\u001b[0m         labels_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mloc[idx:idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# Tüm etiketlerin aynı olup olmadığını kontrol et\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:11735\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  11661\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  11662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  11663\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11664\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  11665\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11733\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  11734\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 11735\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array()\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5980\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[0;32m   5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n\u001b[1;32m-> 5980\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_protect_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5968\u001b[0m, in \u001b[0;36mNDFrame._protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f()\n\u001b[0;32m   5967\u001b[0m blocks_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m-> 5968\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m!=\u001b[39m blocks_before:\n\u001b[0;32m   5970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5978\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[1;32m-> 5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.consolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    687\u001b[0m bm\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 688\u001b[0m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1870\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1868\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1870\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate_with_refs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2347\u001b[0m, in \u001b[0;36m_consolidate_with_refs\u001b[1;34m(blocks, refs)\u001b[0m\n\u001b[0;32m   2345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks_refs \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[0;32m   2346\u001b[0m     group_blocks, group_refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(group_blocks_refs)))\n\u001b[1;32m-> 2347\u001b[0m     merged_blocks, consolidated \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2350\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m consolidated:\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2385\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2382\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2384\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2385\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2386\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2388\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for features, labels in train_loader:\n",
    "        print(labels[epoch])\n",
    "        print(features.shape)\n",
    "        print(labels.shape)\n",
    "        print(features.dtype)\n",
    "        print(labels.dtype)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.3070\n",
      "Epoch [2/30], Loss: 0.5079\n",
      "Epoch [3/30], Loss: 0.4306\n",
      "Epoch [4/30], Loss: 0.2730\n",
      "Epoch [5/30], Loss: 0.2492\n",
      "Epoch [6/30], Loss: 0.3204\n",
      "Epoch [7/30], Loss: 0.5115\n",
      "Epoch [8/30], Loss: 0.4417\n",
      "Epoch [9/30], Loss: 0.5731\n",
      "Epoch [10/30], Loss: 0.3044\n",
      "Epoch [11/30], Loss: 0.2926\n",
      "Epoch [12/30], Loss: 0.5859\n",
      "Epoch [13/30], Loss: 0.4712\n",
      "Epoch [14/30], Loss: 0.3333\n",
      "Epoch [15/30], Loss: 0.3717\n",
      "Epoch [16/30], Loss: 0.3156\n",
      "Epoch [17/30], Loss: 0.7390\n",
      "Epoch [18/30], Loss: 0.6033\n",
      "Epoch [19/30], Loss: 0.4701\n",
      "Epoch [20/30], Loss: 0.1227\n",
      "Epoch [21/30], Loss: 0.2988\n",
      "Epoch [22/30], Loss: 0.3505\n",
      "Epoch [23/30], Loss: 0.3796\n",
      "Epoch [24/30], Loss: 0.5826\n",
      "Epoch [25/30], Loss: 0.2763\n",
      "Epoch [26/30], Loss: 0.4610\n",
      "Epoch [27/30], Loss: 0.4063\n",
      "Epoch [28/30], Loss: 0.8217\n",
      "Epoch [29/30], Loss: 0.2761\n",
      "Epoch [30/30], Loss: 0.3778\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    " \n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "   model.train()\n",
    "   for features, labels in train_loader:\n",
    "      features, labels = features.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()  # Gradyanları sıfırla\n",
    "      outputs = model(features) \n",
    "      outputs = torch.squeeze(outputs)  # Fazladan boyutu kaldır\n",
    "\n",
    "      labels = labels.float()\n",
    "      \n",
    "      #print(outputs.shape)\n",
    "      #print(labels.shape)  # Modelden tahmin al\n",
    "      loss = criterion(outputs, labels)  # Kayıp hesapla\n",
    "      loss.backward()  # Geri yayılım\n",
    "      optimizer.step()  # Ağı güncelle\n",
    "   print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2951, Accuracy: 0.8844\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0  \n",
    "correct_predictions = 0 \n",
    "total_predictions = 0  \n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        \n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        # Fazladan boyut varsa kaldır\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Tahminler: outputs > 0.5 (Sigmoid aktivasyonu sonucu) # buna gerek yok , normalde denemek için\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2951, Accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "# Test moduna geç\n",
    "model.eval()\n",
    "test_loss = 0.0 \n",
    "correct_predictions = 0  \n",
    "total_predictions = 0 \n",
    "# Test sırasında gradient hesaplanmayacak\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        # Verileri GPU'ya gönder\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        \n",
    "        # Label'ları float'a çevir (BCEWithLogitsLoss için)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Tahminler: Sigmoid gerekmez, direkt olarak 0 ile 1 karşılaştırması yapılır #bcelogits kullandığımız için\n",
    "        predicted = (outputs > 0).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "torch.save(model.state_dict(), 'model_weights_ts_mixer_output_23_09.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli tanımla (aynı yapı ile)\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.to(device)  # Modeli uygun cihaza gönder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on katmanı sigmoide çevirebilir miyiz ? \n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "Evet, son katmanı sigmoid aktivasyon fonksiyonuna çevirebilirsiniz. Eğer iki sınıflı bir problem üzerinde çalışıyorsanız ve çıkış olarak tek bir değer (0 ile 1 arasında) almak istiyorsanız, son katmanın çıkışını sigmoid aktivasyonu ile uygulamak mantıklıdır.\n",
    "\n",
    "Bunu yapmak için son katmanı şu şekilde güncelleyebilirsiniz:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "Sonrasında modelin çıkışına sigmoid aktivasyonunu eklemeniz gerekir:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Forward pass içinde\n",
    "outputs = model(x)\n",
    "outputs = torch.sigmoid(outputs)\n",
    "Bu durumda, kayıp fonksiyonu olarak BCELoss (Binary Cross-Entropy Loss) kullanmalısınız. Yani, hedef değerlerinizin de 0 veya 1 şeklinde olmasına dikkat edin.\n",
    "\n",
    "Özetle, son katmanı sigmoid aktivasyonu ile kullanmak için sadece çıkışı bu şekilde değiştirmelisiniz.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Şunu dedin:\n",
    "bunu nerede değiştirebilirim tsmixer için ? :self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "TSMixer modelinde son katmanı değiştirmek için, genellikle modelin forward metodunun son aşamasındaki çıkış katmanında bir lineer katman kullanılır. self.temporal_projection veya benzeri bir isimle tanımlanmış bir lineer katman son katman olarak görev alıyor olabilir. Bu katmanı değiştirmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "TSMixer modelini bulun: Modelin __init__ fonksiyonunda, self.temporal_projection benzeri bir lineer katmanın tanımlı olduğu yeri bulun.\n",
    "\n",
    "Son katmanı güncelleyin: Eğer out_features kısmı iki sınıflı bir problem içinse, bunu 1 yaparak sigmoid aktivasyonu ile çalışacak şekilde güncelleyebilirsiniz. Örneğin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)\n",
    "Sigmoid aktivasyonunu ekleyin: Modelin forward fonksiyonunda, self.temporal_projection kısmından hemen sonra bir sigmoid aktivasyonu ekleyin. Örneğin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "def forward(self, x):\n",
    "    # Diğer katmanlar...\n",
    "    x = self.temporal_projection(x)\n",
    "    x = torch.sigmoid(x)  # Sigmoid aktivasyonunu burada ekleyin\n",
    "    return x\n",
    "Örnek TSMixer Yapısı:\n",
    "python\n",
    "Kodu kopyala\n",
    "class TSMixer(nn.Module):\n",
    "    def __init__(self, sequence_length, prediction_length, input_channels, output_channels):\n",
    "        super(TSMixer, self).__init__()\n",
    "        self.mixer_layers = nn.ModuleList([...])  # Diğer katmanlar\n",
    "        self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)  # Değiştirilen son katman\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TSMixer'de diğer katmanlar ve işlemler\n",
    "        x = self.temporal_projection(x)\n",
    "        x = torch.sigmoid(x)  # Sigmoid aktivasyon\n",
    "        return x\n",
    "Bu güncellemeleri yaptıktan sonra, model iki sınıflı problemde sigmoid çıkış verecek ve BCELoss ile uyumlu olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
