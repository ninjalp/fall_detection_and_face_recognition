{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "from torchtsmixer import TSMixer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data_imu_birlestirilmis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class Name\"]=label_encoder.fit_transform(df[\"Class Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falling' 'not_falling']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>gz</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.091892</td>\n",
       "      <td>8.707838</td>\n",
       "      <td>1.765225</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>1900-01-01 17:44:42.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.083568</td>\n",
       "      <td>8.732087</td>\n",
       "      <td>1.765318</td>\n",
       "      <td>-0.036781</td>\n",
       "      <td>0.064346</td>\n",
       "      <td>-0.036686</td>\n",
       "      <td>1900-01-01 17:44:42.020000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.075247</td>\n",
       "      <td>8.756325</td>\n",
       "      <td>1.765411</td>\n",
       "      <td>-0.037166</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>-0.036976</td>\n",
       "      <td>1900-01-01 17:44:42.040000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.066932</td>\n",
       "      <td>8.780539</td>\n",
       "      <td>1.765503</td>\n",
       "      <td>-0.037551</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>1900-01-01 17:44:42.060000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.058625</td>\n",
       "      <td>8.804720</td>\n",
       "      <td>1.765596</td>\n",
       "      <td>-0.037936</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>-0.037553</td>\n",
       "      <td>1900-01-01 17:44:42.080000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51645</th>\n",
       "      <td>51645</td>\n",
       "      <td>1.611913</td>\n",
       "      <td>8.047413</td>\n",
       "      <td>-3.202833</td>\n",
       "      <td>-0.106623</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.050371</td>\n",
       "      <td>1900-01-01 17:59:15.899794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51646</th>\n",
       "      <td>51646</td>\n",
       "      <td>1.626502</td>\n",
       "      <td>8.043946</td>\n",
       "      <td>-3.201882</td>\n",
       "      <td>-0.118920</td>\n",
       "      <td>0.123886</td>\n",
       "      <td>-0.071806</td>\n",
       "      <td>1900-01-01 17:59:15.919794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51647</th>\n",
       "      <td>51647</td>\n",
       "      <td>1.641042</td>\n",
       "      <td>8.040466</td>\n",
       "      <td>-3.200937</td>\n",
       "      <td>-0.131261</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>-0.093307</td>\n",
       "      <td>1900-01-01 17:59:15.939794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51648</th>\n",
       "      <td>51648</td>\n",
       "      <td>1.655544</td>\n",
       "      <td>8.036974</td>\n",
       "      <td>-3.199998</td>\n",
       "      <td>-0.143635</td>\n",
       "      <td>0.202538</td>\n",
       "      <td>-0.114858</td>\n",
       "      <td>1900-01-01 17:59:15.959793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51649</th>\n",
       "      <td>51649</td>\n",
       "      <td>1.670022</td>\n",
       "      <td>8.033476</td>\n",
       "      <td>-3.199062</td>\n",
       "      <td>-0.156031</td>\n",
       "      <td>0.241975</td>\n",
       "      <td>-0.136441</td>\n",
       "      <td>1900-01-01 17:59:15.979793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51650 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        ax        ay        az        gx        gy        gz  \\\n",
       "0               0  1.091892  8.707838  1.765225 -0.036396  0.063694 -0.036396   \n",
       "1               1  1.083568  8.732087  1.765318 -0.036781  0.064346 -0.036686   \n",
       "2               2  1.075247  8.756325  1.765411 -0.037166  0.064996 -0.036976   \n",
       "3               3  1.066932  8.780539  1.765503 -0.037551  0.065642 -0.037265   \n",
       "4               4  1.058625  8.804720  1.765596 -0.037936  0.066281 -0.037553   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "51645       51645  1.611913  8.047413 -3.202833 -0.106623  0.084735 -0.050371   \n",
       "51646       51646  1.626502  8.043946 -3.201882 -0.118920  0.123886 -0.071806   \n",
       "51647       51647  1.641042  8.040466 -3.200937 -0.131261  0.163164 -0.093307   \n",
       "51648       51648  1.655544  8.036974 -3.199998 -0.143635  0.202538 -0.114858   \n",
       "51649       51649  1.670022  8.033476 -3.199062 -0.156031  0.241975 -0.136441   \n",
       "\n",
       "                        timestamp  Class Name  \n",
       "0      1900-01-01 17:44:42.000000           1  \n",
       "1      1900-01-01 17:44:42.020000           1  \n",
       "2      1900-01-01 17:44:42.040000           1  \n",
       "3      1900-01-01 17:44:42.060000           1  \n",
       "4      1900-01-01 17:44:42.080000           1  \n",
       "...                           ...         ...  \n",
       "51645  1900-01-01 17:59:15.899794           1  \n",
       "51646  1900-01-01 17:59:15.919794           1  \n",
       "51647  1900-01-01 17:59:15.939794           1  \n",
       "51648  1900-01-01 17:59:15.959793           1  \n",
       "51649  1900-01-01 17:59:15.979793           1  \n",
       "\n",
       "[51650 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51650 entries, 0 to 51649\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  51650 non-null  int64  \n",
      " 1   ax          51650 non-null  float64\n",
      " 2   ay          51650 non-null  float64\n",
      " 3   az          51650 non-null  float64\n",
      " 4   gx          51650 non-null  float64\n",
      " 5   gy          51650 non-null  float64\n",
      " 6   gz          51650 non-null  float64\n",
      " 7   timestamp   51650 non-null  object \n",
      " 8   Class Name  51650 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Veriler Ã¼zerinde standartlaÅŸtÄ±rma yapmak istiyorsanÄ±z, verileri modelinize vermeden Ã¶nce StandardScaler gibi bir Ã¶lÃ§ekleyici ile iÅŸleyebilirsiniz. Ä°ÅŸte nasÄ±l ekleyebileceÄŸinizin bir Ã¶rneÄŸi:\n",
    "\n",
    "StandartlaÅŸtÄ±rmayÄ± Eklemek Ä°Ã§in:\n",
    "\n",
    "StandardScaler kullanÄ±larak her bir ax, ay, az, gx, gy, gz sÃ¼tunu standartlaÅŸtÄ±rÄ±lÄ±yor (ortalamasÄ± 0, varyansÄ± 1 olacak ÅŸekilde).\n",
    "Bu iÅŸlemi __getitem__ fonksiyonu yerine, __init__ fonksiyonunda tÃ¼m veri setine uygulayarak yapÄ±yoruz. Bu sayede veriler model eÄŸitimi Ã¶ncesinde Ã¶lÃ§eklendirilmiÅŸ oluyor.\n",
    "StandartlaÅŸtÄ±rma, modelin daha hÄ±zlÄ± ve kararlÄ± bir ÅŸekilde Ã¶ÄŸrenmesine yardÄ±mcÄ± olabilir, Ã§Ã¼nkÃ¼ girdi verilerindeki farklÄ± bÃ¼yÃ¼klÃ¼klerdeki Ã¶zelliklerin etkilerini dengeleyerek modelin dikkatini Ã¶nemli desenlere yÃ¶nlendirir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import stats\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.dataframe[self.features] = self.scaler.fit_transform(self.dataframe[self.features])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         \n",
    "        features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "        \n",
    "        \n",
    "        label = self.dataframe.loc[idx + self.sequence_length - 1, self.labels]\n",
    "        \n",
    "         \n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class TSMixerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.dataframe[self.features] = self.scaler.fit_transform(self.dataframe[self.features])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "            labels_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.labels].values\n",
    "\n",
    "            # TÃ¼m etiketlerin aynÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et\n",
    "            if len(set(labels_sequence)) == 1:  # TÃ¼m etiketler aynÄ±\n",
    "                label = labels_sequence[0]\n",
    "                break  # AynÄ± etiket bulundu, dÃ¶ngÃ¼den Ã§Ä±k\n",
    "\n",
    "            # FarklÄ± etiketler varsa, bir sonraki indeksi kontrol et\n",
    "            idx += 1\n",
    "            if idx + self.sequence_length > len(self.dataframe):  # SÄ±nÄ±r kontrolÃ¼\n",
    "                raise IndexError(\"Veri setinde uygun pencere kalmadÄ±.\")\n",
    "\n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)  # (sequence_length, features_count)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TSMixerDataset(dataframe)\n",
    "\n",
    " \n",
    "labels = dataset.dataframe['Class Name'].values[:len(dataset)]   \n",
    "\n",
    " \n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    " \n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, stratify=labels)\n",
    " \n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 41300\n",
      "Test dataset size: 10326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1973,  1.4236, -0.3150,  0.0243,  0.1950,  1.7694],\n",
       "         [-0.1946,  1.4154, -0.3331,  0.0300,  0.1794,  1.7647],\n",
       "         [-0.1915,  1.4055, -0.3514,  0.0356,  0.1629,  1.7583],\n",
       "         [-0.1877,  1.3941, -0.3697,  0.0412,  0.1455,  1.7501],\n",
       "         [-0.1835,  1.3811, -0.3880,  0.0468,  0.1273,  1.7402],\n",
       "         [-0.1787,  1.3667, -0.4063,  0.0525,  0.1084,  1.7287],\n",
       "         [-0.1732,  1.3509, -0.4244,  0.0582,  0.0889,  1.7158],\n",
       "         [-0.1672,  1.3338, -0.4425,  0.0640,  0.0688,  1.7013],\n",
       "         [-0.1605,  1.3153, -0.4603,  0.0699,  0.0484,  1.6855],\n",
       "         [-0.1531,  1.2957, -0.4779,  0.0760,  0.0276,  1.6684],\n",
       "         [-0.1451,  1.2748, -0.4951,  0.0822,  0.0066,  1.6500],\n",
       "         [-0.1363,  1.2528, -0.5120,  0.0886, -0.0146,  1.6304],\n",
       "         [-0.1268,  1.2297, -0.5285,  0.0952, -0.0358,  1.6097],\n",
       "         [-0.1165,  1.2057, -0.5445,  0.1021, -0.0570,  1.5880],\n",
       "         [-0.1055,  1.1806, -0.5600,  0.1092, -0.0781,  1.5653],\n",
       "         [-0.0936,  1.1546, -0.5749,  0.1167, -0.0990,  1.5417],\n",
       "         [-0.0808,  1.1278, -0.5892,  0.1244, -0.1195,  1.5173],\n",
       "         [-0.0672,  1.1001, -0.6028,  0.1325, -0.1397,  1.4921],\n",
       "         [-0.0528,  1.0717, -0.6157,  0.1409, -0.1594,  1.4663],\n",
       "         [-0.0374,  1.0427, -0.6277,  0.1498, -0.1785,  1.4398],\n",
       "         [-0.0210,  1.0129, -0.6389,  0.1590, -0.1970,  1.4127],\n",
       "         [-0.0037,  0.9826, -0.6493,  0.1687, -0.2147,  1.3852],\n",
       "         [ 0.0145,  0.9517, -0.6586,  0.1788, -0.2316,  1.3572],\n",
       "         [ 0.0338,  0.9204, -0.6670,  0.1895, -0.2475,  1.3290],\n",
       "         [ 0.0542,  0.8886, -0.6743,  0.2006, -0.2624,  1.3004]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25  \n",
    "prediction_length = 1  \n",
    "input_channels = 6 \n",
    "output_channels = 1\n",
    "\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "criterion = criterion = nn.BCEWithLogitsLoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsmixer accuracy , lstmden daha dÃ¼ÅŸÃ¼k , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m features, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(labels[epoch])\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m, in \u001b[0;36mTSMixerDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m         features_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m:\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     22\u001b[0m         labels_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mloc[idx:idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# TÃ¼m etiketlerin aynÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:11735\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  11661\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  11662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  11663\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11664\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  11665\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11733\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  11734\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 11735\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array()\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5980\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[0;32m   5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n\u001b[1;32m-> 5980\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_protect_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5968\u001b[0m, in \u001b[0;36mNDFrame._protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f()\n\u001b[0;32m   5967\u001b[0m blocks_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m-> 5968\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m!=\u001b[39m blocks_before:\n\u001b[0;32m   5970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:5978\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[1;32m-> 5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.consolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    687\u001b[0m bm\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 688\u001b[0m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1870\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1868\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1870\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate_with_refs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2347\u001b[0m, in \u001b[0;36m_consolidate_with_refs\u001b[1;34m(blocks, refs)\u001b[0m\n\u001b[0;32m   2345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks_refs \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[0;32m   2346\u001b[0m     group_blocks, group_refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(group_blocks_refs)))\n\u001b[1;32m-> 2347\u001b[0m     merged_blocks, consolidated \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2350\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m consolidated:\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2385\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2382\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2384\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2385\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2386\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2388\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for features, labels in train_loader:\n",
    "        print(labels[epoch])\n",
    "        print(features.shape)\n",
    "        print(labels.shape)\n",
    "        print(features.dtype)\n",
    "        print(labels.dtype)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.3070\n",
      "Epoch [2/30], Loss: 0.5079\n",
      "Epoch [3/30], Loss: 0.4306\n",
      "Epoch [4/30], Loss: 0.2730\n",
      "Epoch [5/30], Loss: 0.2492\n",
      "Epoch [6/30], Loss: 0.3204\n",
      "Epoch [7/30], Loss: 0.5115\n",
      "Epoch [8/30], Loss: 0.4417\n",
      "Epoch [9/30], Loss: 0.5731\n",
      "Epoch [10/30], Loss: 0.3044\n",
      "Epoch [11/30], Loss: 0.2926\n",
      "Epoch [12/30], Loss: 0.5859\n",
      "Epoch [13/30], Loss: 0.4712\n",
      "Epoch [14/30], Loss: 0.3333\n",
      "Epoch [15/30], Loss: 0.3717\n",
      "Epoch [16/30], Loss: 0.3156\n",
      "Epoch [17/30], Loss: 0.7390\n",
      "Epoch [18/30], Loss: 0.6033\n",
      "Epoch [19/30], Loss: 0.4701\n",
      "Epoch [20/30], Loss: 0.1227\n",
      "Epoch [21/30], Loss: 0.2988\n",
      "Epoch [22/30], Loss: 0.3505\n",
      "Epoch [23/30], Loss: 0.3796\n",
      "Epoch [24/30], Loss: 0.5826\n",
      "Epoch [25/30], Loss: 0.2763\n",
      "Epoch [26/30], Loss: 0.4610\n",
      "Epoch [27/30], Loss: 0.4063\n",
      "Epoch [28/30], Loss: 0.8217\n",
      "Epoch [29/30], Loss: 0.2761\n",
      "Epoch [30/30], Loss: 0.3778\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    " \n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "   model.train()\n",
    "   for features, labels in train_loader:\n",
    "      features, labels = features.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()  # GradyanlarÄ± sÄ±fÄ±rla\n",
    "      outputs = model(features) \n",
    "      outputs = torch.squeeze(outputs)  # Fazladan boyutu kaldÄ±r\n",
    "\n",
    "      labels = labels.float()\n",
    "      \n",
    "      #print(outputs.shape)\n",
    "      #print(labels.shape)  # Modelden tahmin al\n",
    "      loss = criterion(outputs, labels)  # KayÄ±p hesapla\n",
    "      loss.backward()  # Geri yayÄ±lÄ±m\n",
    "      optimizer.step()  # AÄŸÄ± gÃ¼ncelle\n",
    "   print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2951, Accuracy: 0.8844\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0  \n",
    "correct_predictions = 0 \n",
    "total_predictions = 0  \n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        \n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        # Fazladan boyut varsa kaldÄ±r\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Tahminler: outputs > 0.5 (Sigmoid aktivasyonu sonucu) # buna gerek yok , normalde denemek iÃ§in\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2951, Accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "# Test moduna geÃ§\n",
    "model.eval()\n",
    "test_loss = 0.0 \n",
    "correct_predictions = 0  \n",
    "total_predictions = 0 \n",
    "# Test sÄ±rasÄ±nda gradient hesaplanmayacak\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        # Verileri GPU'ya gÃ¶nder\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        \n",
    "        # Label'larÄ± float'a Ã§evir (BCEWithLogitsLoss iÃ§in)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Tahminler: Sigmoid gerekmez, direkt olarak 0 ile 1 karÅŸÄ±laÅŸtÄ±rmasÄ± yapÄ±lÄ±r #bcelogits kullandÄ±ÄŸÄ±mÄ±z iÃ§in\n",
    "        predicted = (outputs > 0).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "torch.save(model.state_dict(), 'model_weights_ts_mixer_output_23_09.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli tanÄ±mla (aynÄ± yapÄ± ile)\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.to(device)  # Modeli uygun cihaza gÃ¶nder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on katmanÄ± sigmoide Ã§evirebilir miyiz ? \n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "Evet, son katmanÄ± sigmoid aktivasyon fonksiyonuna Ã§evirebilirsiniz. EÄŸer iki sÄ±nÄ±flÄ± bir problem Ã¼zerinde Ã§alÄ±ÅŸÄ±yorsanÄ±z ve Ã§Ä±kÄ±ÅŸ olarak tek bir deÄŸer (0 ile 1 arasÄ±nda) almak istiyorsanÄ±z, son katmanÄ±n Ã§Ä±kÄ±ÅŸÄ±nÄ± sigmoid aktivasyonu ile uygulamak mantÄ±klÄ±dÄ±r.\n",
    "\n",
    "Bunu yapmak iÃ§in son katmanÄ± ÅŸu ÅŸekilde gÃ¼ncelleyebilirsiniz:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "SonrasÄ±nda modelin Ã§Ä±kÄ±ÅŸÄ±na sigmoid aktivasyonunu eklemeniz gerekir:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Forward pass iÃ§inde\n",
    "outputs = model(x)\n",
    "outputs = torch.sigmoid(outputs)\n",
    "Bu durumda, kayÄ±p fonksiyonu olarak BCELoss (Binary Cross-Entropy Loss) kullanmalÄ±sÄ±nÄ±z. Yani, hedef deÄŸerlerinizin de 0 veya 1 ÅŸeklinde olmasÄ±na dikkat edin.\n",
    "\n",
    "Ã–zetle, son katmanÄ± sigmoid aktivasyonu ile kullanmak iÃ§in sadece Ã§Ä±kÄ±ÅŸÄ± bu ÅŸekilde deÄŸiÅŸtirmelisiniz.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Åžunu dedin:\n",
    "bunu nerede deÄŸiÅŸtirebilirim tsmixer iÃ§in ? :self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "TSMixer modelinde son katmanÄ± deÄŸiÅŸtirmek iÃ§in, genellikle modelin forward metodunun son aÅŸamasÄ±ndaki Ã§Ä±kÄ±ÅŸ katmanÄ±nda bir lineer katman kullanÄ±lÄ±r. self.temporal_projection veya benzeri bir isimle tanÄ±mlanmÄ±ÅŸ bir lineer katman son katman olarak gÃ¶rev alÄ±yor olabilir. Bu katmanÄ± deÄŸiÅŸtirmek iÃ§in ÅŸu adÄ±mlarÄ± izleyebilirsiniz:\n",
    "\n",
    "TSMixer modelini bulun: Modelin __init__ fonksiyonunda, self.temporal_projection benzeri bir lineer katmanÄ±n tanÄ±mlÄ± olduÄŸu yeri bulun.\n",
    "\n",
    "Son katmanÄ± gÃ¼ncelleyin: EÄŸer out_features kÄ±smÄ± iki sÄ±nÄ±flÄ± bir problem iÃ§inse, bunu 1 yaparak sigmoid aktivasyonu ile Ã§alÄ±ÅŸacak ÅŸekilde gÃ¼ncelleyebilirsiniz. Ã–rneÄŸin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)\n",
    "Sigmoid aktivasyonunu ekleyin: Modelin forward fonksiyonunda, self.temporal_projection kÄ±smÄ±ndan hemen sonra bir sigmoid aktivasyonu ekleyin. Ã–rneÄŸin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "def forward(self, x):\n",
    "    # DiÄŸer katmanlar...\n",
    "    x = self.temporal_projection(x)\n",
    "    x = torch.sigmoid(x)  # Sigmoid aktivasyonunu burada ekleyin\n",
    "    return x\n",
    "Ã–rnek TSMixer YapÄ±sÄ±:\n",
    "python\n",
    "Kodu kopyala\n",
    "class TSMixer(nn.Module):\n",
    "    def __init__(self, sequence_length, prediction_length, input_channels, output_channels):\n",
    "        super(TSMixer, self).__init__()\n",
    "        self.mixer_layers = nn.ModuleList([...])  # DiÄŸer katmanlar\n",
    "        self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)  # DeÄŸiÅŸtirilen son katman\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TSMixer'de diÄŸer katmanlar ve iÅŸlemler\n",
    "        x = self.temporal_projection(x)\n",
    "        x = torch.sigmoid(x)  # Sigmoid aktivasyon\n",
    "        return x\n",
    "Bu gÃ¼ncellemeleri yaptÄ±ktan sonra, model iki sÄ±nÄ±flÄ± problemde sigmoid Ã§Ä±kÄ±ÅŸ verecek ve BCELoss ile uyumlu olacaktÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
