{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "from torchtsmixer import TSMixer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data_imu_birlestirilmis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class Name\"]=label_encoder.fit_transform(df[\"Class Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falling' 'not_falling']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>gz</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.091892</td>\n",
       "      <td>8.707838</td>\n",
       "      <td>1.765225</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>1900-01-01 17:44:42.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.083568</td>\n",
       "      <td>8.732087</td>\n",
       "      <td>1.765318</td>\n",
       "      <td>-0.036781</td>\n",
       "      <td>0.064346</td>\n",
       "      <td>-0.036686</td>\n",
       "      <td>1900-01-01 17:44:42.020000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.075247</td>\n",
       "      <td>8.756325</td>\n",
       "      <td>1.765411</td>\n",
       "      <td>-0.037166</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>-0.036976</td>\n",
       "      <td>1900-01-01 17:44:42.040000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.066932</td>\n",
       "      <td>8.780539</td>\n",
       "      <td>1.765503</td>\n",
       "      <td>-0.037551</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>1900-01-01 17:44:42.060000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.058625</td>\n",
       "      <td>8.804720</td>\n",
       "      <td>1.765596</td>\n",
       "      <td>-0.037936</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>-0.037553</td>\n",
       "      <td>1900-01-01 17:44:42.080000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51645</th>\n",
       "      <td>51645</td>\n",
       "      <td>1.611913</td>\n",
       "      <td>8.047413</td>\n",
       "      <td>-3.202833</td>\n",
       "      <td>-0.106623</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.050371</td>\n",
       "      <td>1900-01-01 17:59:15.899794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51646</th>\n",
       "      <td>51646</td>\n",
       "      <td>1.626502</td>\n",
       "      <td>8.043946</td>\n",
       "      <td>-3.201882</td>\n",
       "      <td>-0.118920</td>\n",
       "      <td>0.123886</td>\n",
       "      <td>-0.071806</td>\n",
       "      <td>1900-01-01 17:59:15.919794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51647</th>\n",
       "      <td>51647</td>\n",
       "      <td>1.641042</td>\n",
       "      <td>8.040466</td>\n",
       "      <td>-3.200937</td>\n",
       "      <td>-0.131261</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>-0.093307</td>\n",
       "      <td>1900-01-01 17:59:15.939794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51648</th>\n",
       "      <td>51648</td>\n",
       "      <td>1.655544</td>\n",
       "      <td>8.036974</td>\n",
       "      <td>-3.199998</td>\n",
       "      <td>-0.143635</td>\n",
       "      <td>0.202538</td>\n",
       "      <td>-0.114858</td>\n",
       "      <td>1900-01-01 17:59:15.959793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51649</th>\n",
       "      <td>51649</td>\n",
       "      <td>1.670022</td>\n",
       "      <td>8.033476</td>\n",
       "      <td>-3.199062</td>\n",
       "      <td>-0.156031</td>\n",
       "      <td>0.241975</td>\n",
       "      <td>-0.136441</td>\n",
       "      <td>1900-01-01 17:59:15.979793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51650 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        ax        ay        az        gx        gy        gz  \\\n",
       "0               0  1.091892  8.707838  1.765225 -0.036396  0.063694 -0.036396   \n",
       "1               1  1.083568  8.732087  1.765318 -0.036781  0.064346 -0.036686   \n",
       "2               2  1.075247  8.756325  1.765411 -0.037166  0.064996 -0.036976   \n",
       "3               3  1.066932  8.780539  1.765503 -0.037551  0.065642 -0.037265   \n",
       "4               4  1.058625  8.804720  1.765596 -0.037936  0.066281 -0.037553   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "51645       51645  1.611913  8.047413 -3.202833 -0.106623  0.084735 -0.050371   \n",
       "51646       51646  1.626502  8.043946 -3.201882 -0.118920  0.123886 -0.071806   \n",
       "51647       51647  1.641042  8.040466 -3.200937 -0.131261  0.163164 -0.093307   \n",
       "51648       51648  1.655544  8.036974 -3.199998 -0.143635  0.202538 -0.114858   \n",
       "51649       51649  1.670022  8.033476 -3.199062 -0.156031  0.241975 -0.136441   \n",
       "\n",
       "                        timestamp  Class Name  \n",
       "0      1900-01-01 17:44:42.000000           1  \n",
       "1      1900-01-01 17:44:42.020000           1  \n",
       "2      1900-01-01 17:44:42.040000           1  \n",
       "3      1900-01-01 17:44:42.060000           1  \n",
       "4      1900-01-01 17:44:42.080000           1  \n",
       "...                           ...         ...  \n",
       "51645  1900-01-01 17:59:15.899794           1  \n",
       "51646  1900-01-01 17:59:15.919794           1  \n",
       "51647  1900-01-01 17:59:15.939794           1  \n",
       "51648  1900-01-01 17:59:15.959793           1  \n",
       "51649  1900-01-01 17:59:15.979793           1  \n",
       "\n",
       "[51650 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51650 entries, 0 to 51649\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  51650 non-null  int64  \n",
      " 1   ax          51650 non-null  float64\n",
      " 2   ay          51650 non-null  float64\n",
      " 3   az          51650 non-null  float64\n",
      " 4   gx          51650 non-null  float64\n",
      " 5   gy          51650 non-null  float64\n",
      " 6   gz          51650 non-null  float64\n",
      " 7   timestamp   51650 non-null  object \n",
      " 8   Class Name  51650 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import stats\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         \n",
    "        features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "        \n",
    "        \n",
    "        label = self.dataframe.loc[idx + self.sequence_length - 1, self.labels]\n",
    "        \n",
    "         \n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(dataframe)\n",
    "\n",
    " \n",
    "labels = dataset.dataframe['Class Name'].values[:len(dataset)]   \n",
    "\n",
    " \n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    " \n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, stratify=labels)\n",
    " \n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 41300\n",
      "Test dataset size: 10326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4.9445,  5.8315, -5.7653, -1.0877,  0.6416,  1.5000],\n",
       "         [-4.9416,  5.9084, -5.7554, -1.1253,  0.6146,  1.4528],\n",
       "         [-4.9381,  5.9928, -5.7448, -1.1576,  0.5893,  1.4022],\n",
       "         [-4.9340,  6.0843, -5.7333, -1.1850,  0.5656,  1.3483],\n",
       "         [-4.9291,  6.1824, -5.7212, -1.2075,  0.5435,  1.2914],\n",
       "         [-4.9235,  6.2868, -5.7083, -1.2254,  0.5229,  1.2316],\n",
       "         [-4.9169,  6.3970, -5.6948, -1.2387,  0.5038,  1.1692],\n",
       "         [-4.9093,  6.5125, -5.6806, -1.2476,  0.4861,  1.1043],\n",
       "         [-4.9006,  6.6329, -5.6658, -1.2524,  0.4698,  1.0373],\n",
       "         [-4.8907,  6.7578, -5.6504, -1.2530,  0.4549,  0.9682],\n",
       "         [-4.8795,  6.8866, -5.6345, -1.2498,  0.4412,  0.8974],\n",
       "         [-4.8669,  7.0190, -5.6180, -1.2428,  0.4288,  0.8250],\n",
       "         [-4.8529,  7.1544, -5.6011, -1.2321,  0.4176,  0.7513],\n",
       "         [-4.8373,  7.2926, -5.5836, -1.2181,  0.4076,  0.6764],\n",
       "         [-4.8201,  7.4329, -5.5658, -1.2008,  0.3987,  0.6006],\n",
       "         [-4.8011,  7.5750, -5.5475, -1.1803,  0.3909,  0.5241],\n",
       "         [-4.7803,  7.7184, -5.5288, -1.1568,  0.3841,  0.4471],\n",
       "         [-4.7576,  7.8627, -5.5097, -1.1306,  0.3783,  0.3698],\n",
       "         [-4.7329,  8.0074, -5.4904, -1.1016,  0.3734,  0.2925],\n",
       "         [-4.7060,  8.1521, -5.4707, -1.0702,  0.3695,  0.2153],\n",
       "         [-4.6770,  8.2964, -5.4507, -1.0364,  0.3664,  0.1385],\n",
       "         [-4.6456,  8.4397, -5.4306, -1.0004,  0.3641,  0.0622],\n",
       "         [-4.6119,  8.5816, -5.4102, -0.9624,  0.3625, -0.0133],\n",
       "         [-4.5757,  8.7218, -5.3896, -0.9224,  0.3617, -0.0878],\n",
       "         [-4.5370,  8.8597, -5.3688, -0.8808,  0.3616, -0.1610]]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25  \n",
    "prediction_length = 1  \n",
    "input_channels = 6 \n",
    "output_channels = 1\n",
    "\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "criterion = criterion = nn.BCEWithLogitsLoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsmixer accuracy , lstmden daha düşük , model daha büyük olduğu için çok epoch yapıcak zaman bulamadım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(0)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n",
      "tensor(1)\n",
      "torch.Size([32, 25, 6])\n",
      "torch.Size([32])\n",
      "torch.float32\n",
      "torch.int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m features, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(labels[epoch])\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\ninja\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     17\u001b[0m features_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mloc[idx:idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     20\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe\u001b[38;5;241m.\u001b[39mloc[idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels]\n\u001b[1;32m---> 23\u001b[0m features_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features_tensor, label_tensor\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for features, labels in train_loader:\n",
    "        print(labels[epoch])\n",
    "        print(features.shape)\n",
    "        print(labels.shape)\n",
    "        print(features.dtype)\n",
    "        print(labels.dtype)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.2923\n",
      "Epoch [2/30], Loss: 0.6124\n",
      "Epoch [3/30], Loss: 0.3773\n",
      "Epoch [4/30], Loss: 0.5748\n",
      "Epoch [5/30], Loss: 0.5072\n",
      "Epoch [6/30], Loss: 0.3454\n",
      "Epoch [7/30], Loss: 0.4554\n",
      "Epoch [8/30], Loss: 0.4064\n",
      "Epoch [9/30], Loss: 0.3735\n",
      "Epoch [10/30], Loss: 0.5938\n",
      "Epoch [11/30], Loss: 0.5227\n",
      "Epoch [12/30], Loss: 0.3338\n",
      "Epoch [13/30], Loss: 0.4750\n",
      "Epoch [14/30], Loss: 0.1925\n",
      "Epoch [15/30], Loss: 0.6370\n",
      "Epoch [16/30], Loss: 0.4262\n",
      "Epoch [17/30], Loss: 0.5484\n",
      "Epoch [18/30], Loss: 0.4662\n",
      "Epoch [19/30], Loss: 0.4665\n",
      "Epoch [20/30], Loss: 0.3755\n",
      "Epoch [21/30], Loss: 0.6407\n",
      "Epoch [22/30], Loss: 0.5032\n",
      "Epoch [23/30], Loss: 0.5378\n",
      "Epoch [24/30], Loss: 0.4979\n",
      "Epoch [25/30], Loss: 0.2835\n",
      "Epoch [26/30], Loss: 0.3315\n",
      "Epoch [27/30], Loss: 0.5176\n",
      "Epoch [28/30], Loss: 0.6908\n",
      "Epoch [29/30], Loss: 0.6035\n",
      "Epoch [30/30], Loss: 0.2388\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    " \n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "   model.train()\n",
    "   for features, labels in train_loader:\n",
    "      features, labels = features.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()  # Gradyanları sıfırla\n",
    "      outputs = model(features) \n",
    "      outputs = torch.squeeze(outputs)  # Fazladan boyutu kaldır\n",
    "\n",
    "      labels = labels.float()\n",
    "      \n",
    "      #print(outputs.shape)\n",
    "      #print(labels.shape)  # Modelden tahmin al\n",
    "      loss = criterion(outputs, labels)  # Kayıp hesapla\n",
    "      loss.backward()  # Geri yayılım\n",
    "      optimizer.step()  # Ağı güncelle\n",
    "   print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3439, Accuracy: 0.8507\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0  \n",
    "correct_predictions = 0 \n",
    "total_predictions = 0  \n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        \n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        # Fazladan boyut varsa kaldır\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Tahminler: outputs > 0.5 (Sigmoid aktivasyonu sonucu) # buna gerek yok , normalde denemek için\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3439, Accuracy: 0.8584\n"
     ]
    }
   ],
   "source": [
    "# Test moduna geç\n",
    "model.eval()\n",
    "test_loss = 0.0 \n",
    "correct_predictions = 0  \n",
    "total_predictions = 0 \n",
    "# Test sırasında gradient hesaplanmayacak\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        # Verileri GPU'ya gönder\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        \n",
    "        # Label'ları float'a çevir (BCEWithLogitsLoss için)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Tahminler: Sigmoid gerekmez, direkt olarak 0 ile 1 karşılaştırması yapılır #bcelogits kullandığımız için\n",
    "        predicted = (outputs > 0).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()   \n",
    "test_correct_predictions = 0   \n",
    "with torch.no_grad():  \n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)   \n",
    "        outputs = torch.squeeze(outputs)   \n",
    "        \n",
    "        \n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        test_correct_predictions += (predicted == labels).sum().item()  # \n",
    "\n",
    "     \n",
    "    test_accuracy = test_correct_predictions / len(test_loader.dataset)   \n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "torch.save(model.state_dict(), 'model_weights_ts_mixer_output_1.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli tanımla (aynı yapı ile)\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.to(device)  # Modeli uygun cihaza gönder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on katmanı sigmoide çevirebilir miyiz ? \n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "Evet, son katmanı sigmoid aktivasyon fonksiyonuna çevirebilirsiniz. Eğer iki sınıflı bir problem üzerinde çalışıyorsanız ve çıkış olarak tek bir değer (0 ile 1 arasında) almak istiyorsanız, son katmanın çıkışını sigmoid aktivasyonu ile uygulamak mantıklıdır.\n",
    "\n",
    "Bunu yapmak için son katmanı şu şekilde güncelleyebilirsiniz:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "Sonrasında modelin çıkışına sigmoid aktivasyonunu eklemeniz gerekir:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Forward pass içinde\n",
    "outputs = model(x)\n",
    "outputs = torch.sigmoid(outputs)\n",
    "Bu durumda, kayıp fonksiyonu olarak BCELoss (Binary Cross-Entropy Loss) kullanmalısınız. Yani, hedef değerlerinizin de 0 veya 1 şeklinde olmasına dikkat edin.\n",
    "\n",
    "Özetle, son katmanı sigmoid aktivasyonu ile kullanmak için sadece çıkışı bu şekilde değiştirmelisiniz.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Şunu dedin:\n",
    "bunu nerede değiştirebilirim tsmixer için ? :self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "TSMixer modelinde son katmanı değiştirmek için, genellikle modelin forward metodunun son aşamasındaki çıkış katmanında bir lineer katman kullanılır. self.temporal_projection veya benzeri bir isimle tanımlanmış bir lineer katman son katman olarak görev alıyor olabilir. Bu katmanı değiştirmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "TSMixer modelini bulun: Modelin __init__ fonksiyonunda, self.temporal_projection benzeri bir lineer katmanın tanımlı olduğu yeri bulun.\n",
    "\n",
    "Son katmanı güncelleyin: Eğer out_features kısmı iki sınıflı bir problem içinse, bunu 1 yaparak sigmoid aktivasyonu ile çalışacak şekilde güncelleyebilirsiniz. Örneğin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)\n",
    "Sigmoid aktivasyonunu ekleyin: Modelin forward fonksiyonunda, self.temporal_projection kısmından hemen sonra bir sigmoid aktivasyonu ekleyin. Örneğin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "def forward(self, x):\n",
    "    # Diğer katmanlar...\n",
    "    x = self.temporal_projection(x)\n",
    "    x = torch.sigmoid(x)  # Sigmoid aktivasyonunu burada ekleyin\n",
    "    return x\n",
    "Örnek TSMixer Yapısı:\n",
    "python\n",
    "Kodu kopyala\n",
    "class TSMixer(nn.Module):\n",
    "    def __init__(self, sequence_length, prediction_length, input_channels, output_channels):\n",
    "        super(TSMixer, self).__init__()\n",
    "        self.mixer_layers = nn.ModuleList([...])  # Diğer katmanlar\n",
    "        self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)  # Değiştirilen son katman\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TSMixer'de diğer katmanlar ve işlemler\n",
    "        x = self.temporal_projection(x)\n",
    "        x = torch.sigmoid(x)  # Sigmoid aktivasyon\n",
    "        return x\n",
    "Bu güncellemeleri yaptıktan sonra, model iki sınıflı problemde sigmoid çıkış verecek ve BCELoss ile uyumlu olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
