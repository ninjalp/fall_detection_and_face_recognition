{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import glob\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data_imu_birlestirilmis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class Name\"]=label_encoder.fit_transform(df[\"Class Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falling' 'not_falling']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>gz</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.091892</td>\n",
       "      <td>8.707838</td>\n",
       "      <td>1.765225</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>1900-01-01 17:44:42.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.083568</td>\n",
       "      <td>8.732087</td>\n",
       "      <td>1.765318</td>\n",
       "      <td>-0.036781</td>\n",
       "      <td>0.064346</td>\n",
       "      <td>-0.036686</td>\n",
       "      <td>1900-01-01 17:44:42.020000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.075247</td>\n",
       "      <td>8.756325</td>\n",
       "      <td>1.765411</td>\n",
       "      <td>-0.037166</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>-0.036976</td>\n",
       "      <td>1900-01-01 17:44:42.040000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.066932</td>\n",
       "      <td>8.780539</td>\n",
       "      <td>1.765503</td>\n",
       "      <td>-0.037551</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>1900-01-01 17:44:42.060000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.058625</td>\n",
       "      <td>8.804720</td>\n",
       "      <td>1.765596</td>\n",
       "      <td>-0.037936</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>-0.037553</td>\n",
       "      <td>1900-01-01 17:44:42.080000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51645</th>\n",
       "      <td>51645</td>\n",
       "      <td>1.611913</td>\n",
       "      <td>8.047413</td>\n",
       "      <td>-3.202833</td>\n",
       "      <td>-0.106623</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.050371</td>\n",
       "      <td>1900-01-01 17:59:15.899794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51646</th>\n",
       "      <td>51646</td>\n",
       "      <td>1.626502</td>\n",
       "      <td>8.043946</td>\n",
       "      <td>-3.201882</td>\n",
       "      <td>-0.118920</td>\n",
       "      <td>0.123886</td>\n",
       "      <td>-0.071806</td>\n",
       "      <td>1900-01-01 17:59:15.919794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51647</th>\n",
       "      <td>51647</td>\n",
       "      <td>1.641042</td>\n",
       "      <td>8.040466</td>\n",
       "      <td>-3.200937</td>\n",
       "      <td>-0.131261</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>-0.093307</td>\n",
       "      <td>1900-01-01 17:59:15.939794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51648</th>\n",
       "      <td>51648</td>\n",
       "      <td>1.655544</td>\n",
       "      <td>8.036974</td>\n",
       "      <td>-3.199998</td>\n",
       "      <td>-0.143635</td>\n",
       "      <td>0.202538</td>\n",
       "      <td>-0.114858</td>\n",
       "      <td>1900-01-01 17:59:15.959793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51649</th>\n",
       "      <td>51649</td>\n",
       "      <td>1.670022</td>\n",
       "      <td>8.033476</td>\n",
       "      <td>-3.199062</td>\n",
       "      <td>-0.156031</td>\n",
       "      <td>0.241975</td>\n",
       "      <td>-0.136441</td>\n",
       "      <td>1900-01-01 17:59:15.979793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51650 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        ax        ay        az        gx        gy        gz  \\\n",
       "0               0  1.091892  8.707838  1.765225 -0.036396  0.063694 -0.036396   \n",
       "1               1  1.083568  8.732087  1.765318 -0.036781  0.064346 -0.036686   \n",
       "2               2  1.075247  8.756325  1.765411 -0.037166  0.064996 -0.036976   \n",
       "3               3  1.066932  8.780539  1.765503 -0.037551  0.065642 -0.037265   \n",
       "4               4  1.058625  8.804720  1.765596 -0.037936  0.066281 -0.037553   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "51645       51645  1.611913  8.047413 -3.202833 -0.106623  0.084735 -0.050371   \n",
       "51646       51646  1.626502  8.043946 -3.201882 -0.118920  0.123886 -0.071806   \n",
       "51647       51647  1.641042  8.040466 -3.200937 -0.131261  0.163164 -0.093307   \n",
       "51648       51648  1.655544  8.036974 -3.199998 -0.143635  0.202538 -0.114858   \n",
       "51649       51649  1.670022  8.033476 -3.199062 -0.156031  0.241975 -0.136441   \n",
       "\n",
       "                        timestamp  Class Name  \n",
       "0      1900-01-01 17:44:42.000000           1  \n",
       "1      1900-01-01 17:44:42.020000           1  \n",
       "2      1900-01-01 17:44:42.040000           1  \n",
       "3      1900-01-01 17:44:42.060000           1  \n",
       "4      1900-01-01 17:44:42.080000           1  \n",
       "...                           ...         ...  \n",
       "51645  1900-01-01 17:59:15.899794           1  \n",
       "51646  1900-01-01 17:59:15.919794           1  \n",
       "51647  1900-01-01 17:59:15.939794           1  \n",
       "51648  1900-01-01 17:59:15.959793           1  \n",
       "51649  1900-01-01 17:59:15.979793           1  \n",
       "\n",
       "[51650 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51650 entries, 0 to 51649\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  51650 non-null  int64  \n",
      " 1   ax          51650 non-null  float64\n",
      " 2   ay          51650 non-null  float64\n",
      " 3   az          51650 non-null  float64\n",
      " 4   gx          51650 non-null  float64\n",
      " 5   gy          51650 non-null  float64\n",
      " 6   gz          51650 non-null  float64\n",
      " 7   timestamp   51650 non-null  object \n",
      " 8   Class Name  51650 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import stats\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.dataframe[self.features] = self.scaler.fit_transform(self.dataframe[self.features])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         \n",
    "        features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "        \n",
    "        \n",
    "        label = self.dataframe.loc[idx + self.sequence_length - 1, self.labels]\n",
    "        \n",
    "         \n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        self.dataframe[self.features] = self.scaler.fit_transform(self.dataframe[self.features])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "            labels_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.labels].values\n",
    "\n",
    "            # TÃ¼m etiketlerin aynÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et\n",
    "            if len(set(labels_sequence)) == 1:  # TÃ¼m etiketler aynÄ±\n",
    "                label = labels_sequence[0]\n",
    "                break  # AynÄ± etiket bulundu, dÃ¶ngÃ¼den Ã§Ä±k\n",
    "\n",
    "            # FarklÄ± etiketler varsa, bir sonraki indeksi kontrol et\n",
    "            idx += 1\n",
    "            if idx + self.sequence_length > len(self.dataframe):  # SÄ±nÄ±r kontrolÃ¼\n",
    "                raise IndexError(\"Veri setinde uygun pencere kalmadÄ±.\")\n",
    "\n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)  # (sequence_length, features_count)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standard scale Ã¶nemli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(dataframe)\n",
    "\n",
    " \n",
    "labels = dataset.dataframe['Class Name'].values[:len(dataset)]   \n",
    "\n",
    " \n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    " \n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, stratify=labels)\n",
    " \n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 41300\n",
      "Test dataset size: 10326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3258,  0.0611,  0.9339, -0.4327, -1.0874, -1.9737],\n",
       "         [ 0.3341,  0.0286,  0.9693, -0.4955, -1.0221, -1.9335],\n",
       "         [ 0.3423, -0.0049,  1.0047, -0.5595, -0.9573, -1.8904],\n",
       "         [ 0.3504, -0.0392,  1.0400, -0.6245, -0.8928, -1.8448],\n",
       "         [ 0.3583, -0.0744,  1.0751, -0.6904, -0.8287, -1.7968],\n",
       "         [ 0.3662, -0.1103,  1.1100, -0.7570, -0.7652, -1.7465],\n",
       "         [ 0.3739, -0.1469,  1.1446, -0.8242, -0.7022, -1.6940],\n",
       "         [ 0.3816, -0.1841,  1.1791, -0.8918, -0.6398, -1.6396],\n",
       "         [ 0.3892, -0.2217,  1.2132, -0.9596, -0.5780, -1.5834],\n",
       "         [ 0.3967, -0.2599,  1.2471, -1.0274, -0.5169, -1.5255],\n",
       "         [ 0.4041, -0.2984,  1.2806, -1.0951, -0.4565, -1.4662],\n",
       "         [ 0.4115, -0.3372,  1.3138, -1.1626, -0.3968, -1.4055],\n",
       "         [ 0.4188, -0.3762,  1.3465, -1.2296, -0.3380, -1.3436],\n",
       "         [ 0.4260, -0.4154,  1.3789, -1.2960, -0.2801, -1.2807],\n",
       "         [ 0.4332, -0.4547,  1.4108, -1.3616, -0.2230, -1.2169],\n",
       "         [ 0.4403, -0.4939,  1.4423, -1.4263, -0.1669, -1.1525],\n",
       "         [ 0.4474, -0.5332,  1.4732, -1.4899, -0.1117, -1.0875],\n",
       "         [ 0.4544, -0.5722,  1.5036, -1.5521, -0.0576, -1.0220],\n",
       "         [ 0.4615, -0.6111,  1.5335, -1.6130, -0.0046, -0.9564],\n",
       "         [ 0.4684, -0.6497,  1.5627, -1.6723,  0.0473, -0.8906],\n",
       "         [ 0.4754, -0.6879,  1.5914, -1.7297,  0.0980, -0.8250],\n",
       "         [ 0.4824, -0.7257,  1.6194, -1.7853,  0.1475, -0.7595],\n",
       "         [ 0.4893, -0.7631,  1.6467, -1.8387,  0.1957, -0.6945],\n",
       "         [ 0.4962, -0.7998,  1.6734, -1.8899,  0.2426, -0.6300],\n",
       "         [ 0.5032, -0.8359,  1.6993, -1.9386,  0.2882, -0.5662]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)   \n",
    "        c_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)   \n",
    "        \n",
    "        out, _ = self.lstm(x, (h_0, c_0))  # LSTM forward\n",
    "        out = self.fc(out[:, -1, :])  # Son zaman adÄ±mÄ±nÄ±n Ã§Ä±ktÄ±sÄ±nÄ± alÄ±r\n",
    "        out = self.sigmoid(out)  # Sigmoid ile iki sÄ±nÄ±fa ayÄ±rÄ±r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 6  # ax, ay, az, gx, gy, gz (6 Ã¶zellik)\n",
    "hidden_size = 24 # Gizli katman boyutu\n",
    "num_layers = 2  # LSTM katman sayÄ±sÄ±\n",
    "output_size = 1  # Binary classification\n",
    "dropout_prob = 0.5  # Dropout oranÄ±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, dropout_prob).to(device)\n",
    "criterion = nn.BCELoss()   \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(6, 24, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=24, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for features,labels in train_loader:\n",
    "        features.labels=features.to(device),labels.to(device)\n",
    "        print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.4074\n",
      "Epoch [2/30], Loss: 0.3831\n",
      "Epoch [3/30], Loss: 0.3751\n",
      "Epoch [4/30], Loss: 0.4785\n",
      "Epoch [5/30], Loss: 0.0717\n",
      "Epoch [6/30], Loss: 0.0890\n",
      "Epoch [7/30], Loss: 0.6156\n",
      "Epoch [8/30], Loss: 0.2453\n",
      "Epoch [9/30], Loss: 0.1239\n",
      "Epoch [10/30], Loss: 0.0703\n",
      "Epoch [11/30], Loss: 0.1962\n",
      "Epoch [12/30], Loss: 0.1446\n",
      "Epoch [13/30], Loss: 0.0746\n",
      "Epoch [14/30], Loss: 0.0079\n",
      "Epoch [15/30], Loss: 0.0899\n",
      "Epoch [16/30], Loss: 0.0651\n",
      "Epoch [17/30], Loss: 0.0727\n",
      "Epoch [18/30], Loss: 0.0524\n",
      "Epoch [19/30], Loss: 0.1302\n",
      "Epoch [20/30], Loss: 0.1158\n",
      "Epoch [21/30], Loss: 0.1043\n",
      "Epoch [22/30], Loss: 0.1362\n",
      "Epoch [23/30], Loss: 0.0383\n",
      "Epoch [24/30], Loss: 0.1839\n",
      "Epoch [25/30], Loss: 0.2975\n",
      "Epoch [26/30], Loss: 0.0191\n",
      "Epoch [27/30], Loss: 0.0095\n",
      "Epoch [28/30], Loss: 0.3149\n",
      "Epoch [29/30], Loss: 0.0500\n",
      "Epoch [30/30], Loss: 0.1176\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features,labels in train_loader:\n",
    "        features,labels=features.to(device),labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs =model(features)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        labels = labels.float()\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0469, Accuracy: 0.9829\n"
     ]
    }
   ],
   "source": [
    "model.eval()   \n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "with torch.no_grad():   \n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(features)\n",
    "        outputs = torch.squeeze(outputs) \n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Tahminleri yap\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    " \n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Loss: {average_test_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "torch.save(model.state_dict(), 'lstm_model__23_09_2024.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, dropout_prob).to(device)\n",
    " \n",
    "model.load_state_dict(torch.load('lstm_model_23_09_.pth'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
