{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "from torchtsmixer import TSMixer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data_imu_birlestirilmis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class Name\"]=label_encoder.fit_transform(df[\"Class Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['falling' 'not_falling']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>gz</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.091892</td>\n",
       "      <td>8.707838</td>\n",
       "      <td>1.765225</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>-0.036396</td>\n",
       "      <td>1900-01-01 17:44:42.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.083568</td>\n",
       "      <td>8.732087</td>\n",
       "      <td>1.765318</td>\n",
       "      <td>-0.036781</td>\n",
       "      <td>0.064346</td>\n",
       "      <td>-0.036686</td>\n",
       "      <td>1900-01-01 17:44:42.020000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.075247</td>\n",
       "      <td>8.756325</td>\n",
       "      <td>1.765411</td>\n",
       "      <td>-0.037166</td>\n",
       "      <td>0.064996</td>\n",
       "      <td>-0.036976</td>\n",
       "      <td>1900-01-01 17:44:42.040000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.066932</td>\n",
       "      <td>8.780539</td>\n",
       "      <td>1.765503</td>\n",
       "      <td>-0.037551</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>-0.037265</td>\n",
       "      <td>1900-01-01 17:44:42.060000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.058625</td>\n",
       "      <td>8.804720</td>\n",
       "      <td>1.765596</td>\n",
       "      <td>-0.037936</td>\n",
       "      <td>0.066281</td>\n",
       "      <td>-0.037553</td>\n",
       "      <td>1900-01-01 17:44:42.080000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51645</th>\n",
       "      <td>51645</td>\n",
       "      <td>1.611913</td>\n",
       "      <td>8.047413</td>\n",
       "      <td>-3.202833</td>\n",
       "      <td>-0.106623</td>\n",
       "      <td>0.084735</td>\n",
       "      <td>-0.050371</td>\n",
       "      <td>1900-01-01 17:59:15.899794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51646</th>\n",
       "      <td>51646</td>\n",
       "      <td>1.626502</td>\n",
       "      <td>8.043946</td>\n",
       "      <td>-3.201882</td>\n",
       "      <td>-0.118920</td>\n",
       "      <td>0.123886</td>\n",
       "      <td>-0.071806</td>\n",
       "      <td>1900-01-01 17:59:15.919794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51647</th>\n",
       "      <td>51647</td>\n",
       "      <td>1.641042</td>\n",
       "      <td>8.040466</td>\n",
       "      <td>-3.200937</td>\n",
       "      <td>-0.131261</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>-0.093307</td>\n",
       "      <td>1900-01-01 17:59:15.939794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51648</th>\n",
       "      <td>51648</td>\n",
       "      <td>1.655544</td>\n",
       "      <td>8.036974</td>\n",
       "      <td>-3.199998</td>\n",
       "      <td>-0.143635</td>\n",
       "      <td>0.202538</td>\n",
       "      <td>-0.114858</td>\n",
       "      <td>1900-01-01 17:59:15.959793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51649</th>\n",
       "      <td>51649</td>\n",
       "      <td>1.670022</td>\n",
       "      <td>8.033476</td>\n",
       "      <td>-3.199062</td>\n",
       "      <td>-0.156031</td>\n",
       "      <td>0.241975</td>\n",
       "      <td>-0.136441</td>\n",
       "      <td>1900-01-01 17:59:15.979793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51650 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        ax        ay        az        gx        gy        gz  \\\n",
       "0               0  1.091892  8.707838  1.765225 -0.036396  0.063694 -0.036396   \n",
       "1               1  1.083568  8.732087  1.765318 -0.036781  0.064346 -0.036686   \n",
       "2               2  1.075247  8.756325  1.765411 -0.037166  0.064996 -0.036976   \n",
       "3               3  1.066932  8.780539  1.765503 -0.037551  0.065642 -0.037265   \n",
       "4               4  1.058625  8.804720  1.765596 -0.037936  0.066281 -0.037553   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "51645       51645  1.611913  8.047413 -3.202833 -0.106623  0.084735 -0.050371   \n",
       "51646       51646  1.626502  8.043946 -3.201882 -0.118920  0.123886 -0.071806   \n",
       "51647       51647  1.641042  8.040466 -3.200937 -0.131261  0.163164 -0.093307   \n",
       "51648       51648  1.655544  8.036974 -3.199998 -0.143635  0.202538 -0.114858   \n",
       "51649       51649  1.670022  8.033476 -3.199062 -0.156031  0.241975 -0.136441   \n",
       "\n",
       "                        timestamp  Class Name  \n",
       "0      1900-01-01 17:44:42.000000           1  \n",
       "1      1900-01-01 17:44:42.020000           1  \n",
       "2      1900-01-01 17:44:42.040000           1  \n",
       "3      1900-01-01 17:44:42.060000           1  \n",
       "4      1900-01-01 17:44:42.080000           1  \n",
       "...                           ...         ...  \n",
       "51645  1900-01-01 17:59:15.899794           1  \n",
       "51646  1900-01-01 17:59:15.919794           1  \n",
       "51647  1900-01-01 17:59:15.939794           1  \n",
       "51648  1900-01-01 17:59:15.959793           1  \n",
       "51649  1900-01-01 17:59:15.979793           1  \n",
       "\n",
       "[51650 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51650 entries, 0 to 51649\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  51650 non-null  int64  \n",
      " 1   ax          51650 non-null  float64\n",
      " 2   ay          51650 non-null  float64\n",
      " 3   az          51650 non-null  float64\n",
      " 4   gx          51650 non-null  float64\n",
      " 5   gy          51650 non-null  float64\n",
      " 6   gz          51650 non-null  float64\n",
      " 7   timestamp   51650 non-null  object \n",
      " 8   Class Name  51650 non-null  int32  \n",
      "dtypes: float64(6), int32(1), int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import stats\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, sequence_length=25):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "        self.labels = \"Class Name\"\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "         \n",
    "        features_sequence = self.dataframe.loc[idx:idx + self.sequence_length - 1, self.features].values.astype(float)\n",
    "        \n",
    "        \n",
    "        label = self.dataframe.loc[idx + self.sequence_length - 1, self.labels]\n",
    "        \n",
    "         \n",
    "        features_tensor = torch.tensor(features_sequence, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, label_tensor\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(dataframe)\n",
    "\n",
    " \n",
    "labels = dataset.dataframe['Class Name'].values[:len(dataset)]   \n",
    "\n",
    " \n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    " \n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, stratify=labels)\n",
    " \n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 41300\n",
      "Test dataset size: 10326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.4228e+00,  9.0348e+00, -3.1842e+00, -1.4843e-01, -3.0723e-01,\n",
       "           7.7309e-01],\n",
       "         [ 2.4026e+00,  9.0280e+00, -3.2306e+00, -1.3303e-01, -2.9372e-01,\n",
       "           7.5192e-01],\n",
       "         [ 2.3810e+00,  9.0209e+00, -3.2772e+00, -1.1716e-01, -2.8020e-01,\n",
       "           7.3203e-01],\n",
       "         [ 2.3582e+00,  9.0134e+00, -3.3238e+00, -1.0085e-01, -2.6670e-01,\n",
       "           7.1340e-01],\n",
       "         [ 2.3343e+00,  9.0055e+00, -3.3702e+00, -8.4120e-02, -2.5323e-01,\n",
       "           6.9602e-01],\n",
       "         [ 2.3093e+00,  8.9973e+00, -3.4164e+00, -6.6986e-02, -2.3980e-01,\n",
       "           6.7989e-01],\n",
       "         [ 2.2833e+00,  8.9888e+00, -3.4621e+00, -4.9470e-02, -2.2644e-01,\n",
       "           6.6500e-01],\n",
       "         [ 2.2566e+00,  8.9800e+00, -3.5072e+00, -3.1592e-02, -2.1316e-01,\n",
       "           6.5134e-01],\n",
       "         [ 2.2291e+00,  8.9709e+00, -3.5515e+00, -1.3373e-02, -1.9997e-01,\n",
       "           6.3890e-01],\n",
       "         [ 2.2009e+00,  8.9616e+00, -3.5949e+00,  5.1685e-03, -1.8689e-01,\n",
       "           6.2768e-01],\n",
       "         [ 2.1723e+00,  8.9520e+00, -3.6372e+00,  2.4011e-02, -1.7394e-01,\n",
       "           6.1766e-01],\n",
       "         [ 2.1433e+00,  8.9423e+00, -3.6783e+00,  4.3134e-02, -1.6113e-01,\n",
       "           6.0884e-01],\n",
       "         [ 2.1139e+00,  8.9324e+00, -3.7180e+00,  6.2518e-02, -1.4848e-01,\n",
       "           6.0121e-01],\n",
       "         [ 2.0844e+00,  8.9223e+00, -3.7561e+00,  8.2142e-02, -1.3601e-01,\n",
       "           5.9476e-01],\n",
       "         [ 2.0548e+00,  8.9121e+00, -3.7925e+00,  1.0199e-01, -1.2373e-01,\n",
       "           5.8948e-01],\n",
       "         [ 2.0252e+00,  8.9018e+00, -3.8271e+00,  1.2203e-01, -1.1165e-01,\n",
       "           5.8537e-01],\n",
       "         [ 1.9957e+00,  8.8914e+00, -3.8596e+00,  1.4226e-01, -9.9804e-02,\n",
       "           5.8241e-01],\n",
       "         [ 1.9665e+00,  8.8809e+00, -3.8900e+00,  1.6264e-01, -8.8194e-02,\n",
       "           5.8060e-01],\n",
       "         [ 1.9376e+00,  8.8704e+00, -3.9180e+00,  1.8316e-01, -7.6840e-02,\n",
       "           5.7992e-01],\n",
       "         [ 1.9092e+00,  8.8599e+00, -3.9435e+00,  2.0381e-01, -6.5758e-02,\n",
       "           5.8038e-01],\n",
       "         [ 1.8813e+00,  8.8494e+00, -3.9664e+00,  2.2455e-01, -5.4965e-02,\n",
       "           5.8196e-01],\n",
       "         [ 1.8540e+00,  8.8389e+00, -3.9865e+00,  2.4537e-01, -4.4476e-02,\n",
       "           5.8465e-01],\n",
       "         [ 1.8276e+00,  8.8284e+00, -4.0036e+00,  2.6625e-01, -3.4307e-02,\n",
       "           5.8845e-01],\n",
       "         [ 1.8020e+00,  8.8180e+00, -4.0175e+00,  2.8716e-01, -2.4476e-02,\n",
       "           5.9335e-01],\n",
       "         [ 1.7774e+00,  8.8077e+00, -4.0282e+00,  3.0810e-01, -1.4997e-02,\n",
       "           5.9933e-01]]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25  \n",
    "prediction_length = 1  \n",
    "input_channels = 6 \n",
    "output_channels = 2 \n",
    "\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.4143\n",
      "Epoch [2/30], Loss: 0.2361\n",
      "Epoch [3/30], Loss: 0.4447\n",
      "Epoch [4/30], Loss: 0.4257\n",
      "Epoch [5/30], Loss: 0.5685\n",
      "Epoch [6/30], Loss: 0.3646\n",
      "Epoch [7/30], Loss: 0.3803\n",
      "Epoch [8/30], Loss: 0.6811\n",
      "Epoch [9/30], Loss: 0.5020\n",
      "Epoch [10/30], Loss: 0.6336\n",
      "Epoch [11/30], Loss: 0.3083\n",
      "Epoch [12/30], Loss: 0.2336\n",
      "Epoch [13/30], Loss: 0.6734\n",
      "Epoch [14/30], Loss: 0.3285\n",
      "Epoch [15/30], Loss: 0.4862\n",
      "Epoch [16/30], Loss: 0.5278\n",
      "Epoch [17/30], Loss: 0.3912\n",
      "Epoch [18/30], Loss: 0.3413\n",
      "Epoch [19/30], Loss: 0.4046\n",
      "Epoch [20/30], Loss: 0.5103\n",
      "Epoch [21/30], Loss: 0.3473\n",
      "Epoch [22/30], Loss: 0.2828\n",
      "Epoch [23/30], Loss: 0.3043\n",
      "Epoch [24/30], Loss: 0.2149\n",
      "Epoch [25/30], Loss: 0.4656\n",
      "Epoch [26/30], Loss: 0.5836\n",
      "Epoch [27/30], Loss: 0.3747\n",
      "Epoch [28/30], Loss: 0.5496\n",
      "Epoch [29/30], Loss: 0.2205\n",
      "Epoch [30/30], Loss: 0.2348\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    " \n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "   model.train()\n",
    "   for features, labels in train_loader:\n",
    "      features, labels = features.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()  # Gradyanları sıfırla\n",
    "      outputs = model(features) \n",
    "      outputs = torch.squeeze(outputs)  # Fazladan boyutu kaldır\n",
    "\n",
    "      labels = labels.long()\n",
    "      #print(outputs.shape)\n",
    "      #print(labels.shape)  # Modelden tahmin al\n",
    "      loss = criterion(outputs, labels)  # Kayıp hesapla\n",
    "      loss.backward()  # Geri yayılım\n",
    "      optimizer.step()  # Ağı güncelle\n",
    "   print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8651\n"
     ]
    }
   ],
   "source": [
    "model.eval()   \n",
    "test_correct_predictions = 0   \n",
    "with torch.no_grad():  \n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)   \n",
    "        outputs = torch.squeeze(outputs)   \n",
    "            \n",
    "        predicted = torch.argmax(outputs, dim=1)   \n",
    "        test_correct_predictions += (predicted == labels).sum().item()  # \n",
    "\n",
    "     \n",
    "    test_accuracy = test_correct_predictions / len(test_loader.dataset)   \n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "torch.save(model.state_dict(), 'model_weights_ts_mixer.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli tanımla (aynı yapı ile)\n",
    "model = TSMixer(sequence_length, prediction_length, input_channels, output_channels)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.to(device)  # Modeli uygun cihaza gönder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on katmanı sigmoide çevirebilir miyiz ? \n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "Evet, son katmanı sigmoid aktivasyon fonksiyonuna çevirebilirsiniz. Eğer iki sınıflı bir problem üzerinde çalışıyorsanız ve çıkış olarak tek bir değer (0 ile 1 arasında) almak istiyorsanız, son katmanın çıkışını sigmoid aktivasyonu ile uygulamak mantıklıdır.\n",
    "\n",
    "Bunu yapmak için son katmanı şu şekilde güncelleyebilirsiniz:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "Sonrasında modelin çıkışına sigmoid aktivasyonunu eklemeniz gerekir:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Forward pass içinde\n",
    "outputs = model(x)\n",
    "outputs = torch.sigmoid(outputs)\n",
    "Bu durumda, kayıp fonksiyonu olarak BCELoss (Binary Cross-Entropy Loss) kullanmalısınız. Yani, hedef değerlerinizin de 0 veya 1 şeklinde olmasına dikkat edin.\n",
    "\n",
    "Özetle, son katmanı sigmoid aktivasyonu ile kullanmak için sadece çıkışı bu şekilde değiştirmelisiniz.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Şunu dedin:\n",
    "bunu nerede değiştirebilirim tsmixer için ? :self.temporal_projection = Linear(in_features=25, out_features=1, bias=True)\n",
    "ChatGPT:\n",
    "ChatGPT\n",
    "TSMixer modelinde son katmanı değiştirmek için, genellikle modelin forward metodunun son aşamasındaki çıkış katmanında bir lineer katman kullanılır. self.temporal_projection veya benzeri bir isimle tanımlanmış bir lineer katman son katman olarak görev alıyor olabilir. Bu katmanı değiştirmek için şu adımları izleyebilirsiniz:\n",
    "\n",
    "TSMixer modelini bulun: Modelin __init__ fonksiyonunda, self.temporal_projection benzeri bir lineer katmanın tanımlı olduğu yeri bulun.\n",
    "\n",
    "Son katmanı güncelleyin: Eğer out_features kısmı iki sınıflı bir problem içinse, bunu 1 yaparak sigmoid aktivasyonu ile çalışacak şekilde güncelleyebilirsiniz. Örneğin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)\n",
    "Sigmoid aktivasyonunu ekleyin: Modelin forward fonksiyonunda, self.temporal_projection kısmından hemen sonra bir sigmoid aktivasyonu ekleyin. Örneğin:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "def forward(self, x):\n",
    "    # Diğer katmanlar...\n",
    "    x = self.temporal_projection(x)\n",
    "    x = torch.sigmoid(x)  # Sigmoid aktivasyonunu burada ekleyin\n",
    "    return x\n",
    "Örnek TSMixer Yapısı:\n",
    "python\n",
    "Kodu kopyala\n",
    "class TSMixer(nn.Module):\n",
    "    def __init__(self, sequence_length, prediction_length, input_channels, output_channels):\n",
    "        super(TSMixer, self).__init__()\n",
    "        self.mixer_layers = nn.ModuleList([...])  # Diğer katmanlar\n",
    "        self.temporal_projection = nn.Linear(in_features=25, out_features=1, bias=True)  # Değiştirilen son katman\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TSMixer'de diğer katmanlar ve işlemler\n",
    "        x = self.temporal_projection(x)\n",
    "        x = torch.sigmoid(x)  # Sigmoid aktivasyon\n",
    "        return x\n",
    "Bu güncellemeleri yaptıktan sonra, model iki sınıflı problemde sigmoid çıkış verecek ve BCELoss ile uyumlu olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSMixer(\n",
       "  (mixer_layers): Sequential(\n",
       "    (0): MixerLayer(\n",
       "      (time_mixing): TimeMixing(\n",
       "        (norm): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=25, out_features=25, bias=True)\n",
       "      )\n",
       "      (feature_mixing): FeatureMixing(\n",
       "        (norm_before): TimeBatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (norm_after): Identity()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=6, out_features=64, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (projection): Linear(in_features=6, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_projection): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
